"use client";

import { useState, useEffect } from 'react';
import { Mic } from 'lucide-react';
import { Button } from '@/components/ui/button';
import { useToast } from "@/hooks/use-toast";
import { useRouter } from 'next/navigation';

export function VoiceRecognitionButton() {
  const { toast } = useToast();
  const [mounted, setMounted] = useState(false);
  const router = useRouter();

  useEffect(() => setMounted(true), []);

  const speak = (text: string) => {
  const utterance = new SpeechSynthesisUtterance(text);
  utterance.lang = "ko-KR";
  speechSynthesis.speak(utterance);
};


  const handleVoiceRecognition = () => {
    const SpeechRecognition =
      (window as any).webkitSpeechRecognition ||
      (window as any).SpeechRecognition;

    if (!SpeechRecognition) {
      toast({
        title: "ì§€ì›ë˜ì§€ ì•ŠìŒ",
        description: "ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
        variant: "destructive",
      });
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = "ko-KR";
    recognition.continuous = false;
    recognition.interimResults = false;

    toast({ title: "ìŒì„± ì¸ì‹", description: "ğŸ¤ ì¸ì‹ ì‹œì‘..." });

    recognition.onstart = () => {
      toast({ title: "ìŒì„± ì¸ì‹", description: "ğŸ¤ ì¸ì‹ ì¤€ë¹„ ì¤‘..." });
    };

    recognition.onresult = (event: SpeechRecognitionEvent) => {
  const text = Array.from(event.results)
    .map((result) => result[0].transcript)
    .join("");

  toast({ title: "ì¸ì‹ ê²°ê³¼", description: text });

  const normalized = text.replace(/\s/g, "");

  // âœ… TTS í•¨ìˆ˜ í˜¸ì¶œ
  const speak = (message: string) => {
    const utterance = new SpeechSynthesisUtterance(message);
    utterance.lang = "ko-KR";
    speechSynthesis.speak(utterance);
  };

  if (normalized.includes("ì¶©ì „ì‹œì‘") || normalized.includes("ì¶©ì „")) {
    speak("ì¶©ì „ì„ ì‹œì‘í•©ë‹ˆë‹¤.");
    router.push("/charging");
  } else if (normalized.includes("ê²°ì œ")) {
    speak("ê²°ì œ í™”ë©´ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.");
    router.push("/payment");
  } else if (normalized.includes("ì²˜ìŒ") || normalized.includes("í™ˆ")) {
    speak("ì²˜ìŒ í™”ë©´ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.");
    router.push("/");
  } else if (normalized.includes("ë„ì›€ë§")) {
    speak("ë„ì›€ë§ í™”ë©´ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.");
    router.push("/help");
  } else if (normalized.includes("ì„¤ì •")) {
    speak("ì„¤ì • í™”ë©´ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.");
    router.push("/settings");
  } else {
    toast({
      title: "ëª…ë ¹ì–´ ì¸ì‹ ì‹¤íŒ¨",
      description: `"${text}" ëª…ë ¹ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.`,
      variant: "destructive",
    });
    speak("ì£„ì†¡í•©ë‹ˆë‹¤. ëª…ë ¹ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.");
  }

  // âœ… ë¡œê·¸ ì €ì¥
  const prevLogs = JSON.parse(localStorage.getItem("voiceLogs") || "[]");
  localStorage.setItem(
    "voiceLogs",
    JSON.stringify([
      ...prevLogs,
      {
        time: new Date().toISOString(),
        command: text,
      },
    ])
  );
};


    recognition.onerror = (event) => {
      toast({
        title: "ì˜¤ë¥˜ ë°œìƒ",
        description: event.error,
        variant: "destructive",
      });
    };

    recognition.onend = () => {
      toast({ title: "ìŒì„± ì¸ì‹", description: "ğŸ¤ ì¸ì‹ ì¢…ë£Œ" });
    };

    recognition.start(); // âœ… ë°˜ë“œì‹œ ë§ˆì§€ë§‰ì— í•œ ë²ˆë§Œ í˜¸ì¶œ
  };

  if (!mounted) return <div style={{ width: '80px', height: '80px' }} />;

  return (
    <Button
      variant="outline"
      onClick={handleVoiceRecognition}
      className="rounded-full w-20 h-20 shadow-md 
                 border 
                 bg-[hsl(220,30%,10%)] text-[hsl(220,15%,85%)] border-[hsl(220,30%,25%)] 
                 hover:bg-[hsl(220,30%,15%)] 
                 dark:bg-white dark:text-[hsl(220,30%,10%)] dark:border-gray-300 
                 dark:hover:bg-gray-200"
      aria-label="Start voice recognition"
    >
      <Mic className="!size-8" strokeWidth={2.5} />
    </Button>
  );
}
